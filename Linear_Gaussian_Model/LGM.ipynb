{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Gaussian Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T13:37:56.892301Z",
     "start_time": "2020-03-16T13:37:56.889638Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxiliary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T13:38:02.057824Z",
     "start_time": "2020-03-16T13:38:02.049715Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Skeleton definition\n",
    "NUI_SKELETON_POSITION_COUNT = 20\n",
    "\n",
    "NONE = -1\n",
    "HIP_CENTER = 0\n",
    "SPINE = 1\n",
    "SHOULDER_CENTER = 2\n",
    "HEAD = 3\n",
    "SHOULDER_LEFT = 4\n",
    "ELBOW_LEFT = 5\n",
    "WRIST_LEFT = 6\n",
    "HAND_LEFT = 7\n",
    "SHOULDER_RIGHT = 8\n",
    "ELBOW_RIGHT = 9\n",
    "WRIST_RIGHT = 10\n",
    "HAND_RIGHT = 11\n",
    "HIP_LEFT = 12\n",
    "KNEE_LEFT = 13\n",
    "ANKLE_LEFT = 14\n",
    "FOOT_LEFT = 15\n",
    "HIP_RIGHT = 16\n",
    "KNEE_RIGHT = 17\n",
    "ANKLE_RIGHT = 18\n",
    "FOOT_RIGHT = 19\n",
    "\n",
    "nui_skeleton_names = ( \\\n",
    "    'HIP_CENTER', 'SPINE', 'SHOULDER_CENTER', 'HEAD', \\\n",
    "    'SHOULDER_LEFT', 'ELBOW_LEFT', 'WRIST_LEFT', 'HAND_LEFT', \\\n",
    "    'SHOULDER_RIGHT', 'ELBOW_RIGHT', 'WRIST_RIGHT', 'HAND_RIGHT', \\\n",
    "    'HIP_LEFT', 'KNEE_LEFT', 'ANKLE_LEFT', 'FOOT_LEFT', \\\n",
    "    'HIP_RIGHT', 'KNEE_RIGHT', 'ANKLE_RIGHT', 'FOOT_RIGHT' )\n",
    "\n",
    "nui_skeleton_conn = ( \\\n",
    "    NONE, \\\n",
    "    HIP_CENTER, \\\n",
    "    SPINE, \\\n",
    "    SHOULDER_CENTER, \\\n",
    "    # Left arm \n",
    "    SHOULDER_CENTER, \\\n",
    "    SHOULDER_LEFT,  \\\n",
    "    ELBOW_LEFT,  \\\n",
    "    WRIST_LEFT,  \\\n",
    "    # Right arm \n",
    "    SHOULDER_CENTER,  \\\n",
    "    SHOULDER_RIGHT,  \\\n",
    "    ELBOW_RIGHT,  \\\n",
    "    WRIST_RIGHT,  \\\n",
    "    # Left leg \n",
    "    HIP_CENTER,  \\\n",
    "    HIP_LEFT,  \\\n",
    "    KNEE_LEFT,  \\\n",
    "    ANKLE_LEFT,  \\\n",
    "    # Right leg \n",
    "    HIP_CENTER,  \\\n",
    "    HIP_RIGHT,  \\\n",
    "    KNEE_RIGHT,  \\\n",
    "    ANKLE_RIGHT,  \\\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T13:38:05.493261Z",
     "start_time": "2020-03-16T13:38:05.489045Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def load_dataset(file=None):\n",
    "    \"\"\"\n",
    "      Returns the data, the labels and the person id for each action\n",
    "    \"\"\"\n",
    "    import scipy.io\n",
    "    \n",
    "    if file is None:\n",
    "        ex = scipy.io.loadmat('data/data.mat')\n",
    "    else:\n",
    "        ex = scipy.io.loadmat(file)\n",
    "        \n",
    "    return ex['data'],ex['labels'],ex['individuals']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def log_normpdf(x, mu, sigma):\n",
    "    \"\"\"\n",
    "      Computes the natural logarithm of the normal probability density function\n",
    "      \n",
    "    \"\"\"\n",
    "    p1 = np.log(1/(np.sqrt(2*np.pi)*sigma))\n",
    "    p2 = ((x-mu)**2)/(2*(sigma**2))\n",
    "    return p1-p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def normalize_logprobs(log_probs):\n",
    "    \"\"\"\n",
    "       Returns the log prob normalized so that when exponenciated\n",
    "       it adds up to 1 (Useful to normalizes logprobs)\n",
    "    \"\"\"\n",
    "    mm = np.max(log_probs)\n",
    "    return log_probs - mm - np.log(np.sum(np.exp(log_probs - mm)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T13:39:37.172514Z",
     "start_time": "2020-03-30T13:39:37.168362Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def my_cov(x,y,w):\n",
    "    \"\"\"\n",
    "      Useful function for fit_linear_gaussian\n",
    "    \"\"\"\n",
    "    return np.sum(w*x*y)/np.sum(w)-np.sum(w*x)*np.sum(w*y)/np.sum(w)/np.sum(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def means_from_betas(betas, instance):\n",
    "    \n",
    "    return betas[0] + betas[1] * instance[0] + betas[2] * instance[1] + betas[3] * instance[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Functions and Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T13:38:10.226913Z",
     "start_time": "2020-03-16T13:38:10.218920Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def fit_gaussian(X, W=None):\n",
    "    \"\"\"\n",
    "      Compute the mean and variance of X, \n",
    "      You can ignore W for the moment\n",
    "    \"\"\"\n",
    "    mean = np.mean(X,axis=0)\n",
    "    variance = np.var(X,axis=0)\n",
    "    sigma = np.sqrt(variance)\n",
    "    return (mean, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T14:10:00.598498Z",
     "start_time": "2020-03-30T14:10:00.588271Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def fit_linear_gaussian(Y,X,W = None):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "      Y: vector of size Dx1 with the observations for the variable\n",
    "      X: matrix DxV with the observations for the parent variables\n",
    "                 of X. V is the number of parent variables\n",
    "      W: vector of size D with the weights of the instances (ignore for the moment)\n",
    "      \n",
    "    Outout:\n",
    "       The betas and sigma\n",
    "    \"\"\"\n",
    "    #We add ones in the first row in numpy\n",
    "    #https://stackoverflow.com/questions/8298797/inserting-a-row-at-a-specific-location-in-a-2d-array-in-numpy\n",
    "    D = X.shape[0]\n",
    "\n",
    "    X1 = np.insert(X, 0, np.ones(D), 1)\n",
    "\n",
    "    V = X1.shape[1]\n",
    "    \n",
    "    lhs = [np.mean(Y * X1[:,i]) for i in range(V)]\n",
    "    lhs = np.asarray(lhs)\n",
    "\n",
    "    #V+1 * D @ D * V+1 = V+1 * V+1\n",
    "    rhs = X1.T @ X1\n",
    "    rhs = rhs/D\n",
    "\n",
    "    betas = np.linalg.inv(rhs) @ lhs\n",
    "\n",
    "    W = np.ones(D)\n",
    "    cov_y = my_cov(Y, Y, W)\n",
    "    cov_x = np.zeros((V, V))\n",
    "    \n",
    "    for i in range(1,V):\n",
    "        for j in range (1,V):\n",
    "            cov_x[i, j] = betas[i] * betas[j] * my_cov(X[:, i-1], X[:, j-1], W)\n",
    "\n",
    "    variance = cov_y - np.matrix.sum(np.matrix(cov_x))\n",
    "    \n",
    "    sigma = np.sqrt(variance)\n",
    "    \n",
    "    if sigma == 0 or type(sigma) == 'complex':                                   \n",
    "        sigma = .01                                                              \n",
    "    else:                                                                        \n",
    "        sigma = sigma + .01\n",
    "\n",
    "    return (betas, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class Jointpart:\n",
    "    def __init__(self, means, sigmas, betas = None):\n",
    "        if betas is None:\n",
    "            self.NaiveBayesModel(means,sigmas)\n",
    "        else:\n",
    "            self.LinearGaussianModel(betas, sigmas)\n",
    "\n",
    "    def NaiveBayesModel(self, means, sigmas):\n",
    "        self.means = means\n",
    "        self.sigmas = sigmas\n",
    "\n",
    "    def LinearGaussianModel(self, betas, sigmas):\n",
    "        self.betas = betas\n",
    "        self.sigmas = sigmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, Graph):\n",
    "        self.connectivity = Graph\n",
    "        self.jointparts = []\n",
    "        \n",
    "        if Graph == None:\n",
    "            self.modelType = \"NB\"\n",
    "        else:\n",
    "            self.modelType = \"LGM\"\n",
    "\n",
    "    def AppendJointParams(self,jointpart):\n",
    "        self.jointparts.append(jointpart)\n",
    "\n",
    "    def SetClassPriors(self,priors):\n",
    "        self.classPriors = priors\n",
    "\n",
    "    def SetNumClasses(self,numClasses):\n",
    "        self.numClasses = numClasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def learn_model(dataset, labels, G=None):\n",
    "    myModel = Model(G)\n",
    "    numJoints = dataset.shape[0]\n",
    "    \n",
    "    unique, counts = np.unique(labels, return_counts=True)\n",
    "    priors = [i/len(labels) for i in counts]\n",
    "    myModel.SetClassPriors(np.asarray(priors))\n",
    "    numClasses = len(unique)\n",
    "    myModel.SetNumClasses(numClasses)\n",
    "    labels = labels.squeeze()\n",
    "    \n",
    "    if myModel.modelType == \"NB\":        \n",
    "        for joint in range(numJoints):\n",
    "            meanList = []\n",
    "            sigmaList = []\n",
    "            for label in unique:\n",
    "                m, s = fit_gaussian(dataset[joint,:,labels[:] == label])\n",
    "                meanList.append(m)\n",
    "                sigmaList.append(s)\n",
    "            \n",
    "            means = np.column_stack(meanList)\n",
    "            sigmas = np.column_stack(sigmaList)\n",
    "            \n",
    "            myModel.AppendJointParams(Jointpart(means,sigmas))\n",
    "        \n",
    "        return myModel\n",
    "        \n",
    "    elif myModel.modelType == \"LGM\":\n",
    "        for joint in range(numJoints):\n",
    "            if myModel.connectivity[joint] == -1:\n",
    "\n",
    "                meanList = []\n",
    "                sigmaList = []\n",
    "                for label in unique:\n",
    "                    m, s = fit_gaussian(dataset[joint,:,labels[:] == label])\n",
    "                    meanList.append(m)\n",
    "                    sigmaList.append(s)\n",
    "\n",
    "                means = np.column_stack(meanList)\n",
    "                sigmas = np.column_stack(sigmaList)\n",
    "\n",
    "                myModel.AppendJointParams(Jointpart(means,sigmas))\n",
    "            \n",
    "            else:\n",
    "                betas = np.zeros((12,4))\n",
    "                sigmas = np.zeros((3,4))\n",
    "\n",
    "                for label in range(numClasses):\n",
    "                    for coordinate in range (3):\n",
    "                        Y = dataset[joint,coordinate,labels[:] == label]\n",
    "                        X = dataset[myModel.connectivity[joint],:,labels[:] == label]\n",
    "                        beta, sigma = fit_linear_gaussian(Y,X)\n",
    "                        betas[coordinate*4:(coordinate+1)*4,label] = beta\n",
    "                        sigmas[coordinate,label] = sigma\n",
    "                        \n",
    "                myModel.AppendJointParams(Jointpart(None,sigmas,betas))\n",
    "\n",
    "        return myModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def classify_instances(instances, model):\n",
    "    output = np.zeros((instances.shape[2], model.numClasses))\n",
    "\n",
    "    for i in range(instances.shape[2]):\n",
    "        logProbs = compute_logprobs(instances[:,:,i],model)\n",
    "        normLogProbs = normalize_logprobs(logProbs)\n",
    "        expProbs = np.exp(normLogProbs)\n",
    "        output[i,:] = expProbs\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_logprobs(example, model):\n",
    "    \"\"\"\n",
    "    \n",
    "       Input\n",
    "           instance: a 20x3 matrix defining body positions of one instance\n",
    "           model: as given by learn_model\n",
    "\n",
    "       Output\n",
    "           l: a vector of len #classes containing the loglikelihhod of the \n",
    "              instance\n",
    "\n",
    "    \"\"\"\n",
    "    output = np.log(model.classPriors)\n",
    "    \n",
    "    if model.modelType == \"NB\":\n",
    "        for label in range(model.numClasses):\n",
    "            for joint in range(example.shape[0]):\n",
    "                for coordinate in range(example.shape[1]):\n",
    "                    output[label] += log_normpdf(example[joint,coordinate],\n",
    "                                                 model.jointparts[joint].means[coordinate,label],\n",
    "                                                 model.jointparts[joint].sigmas[coordinate,label])\n",
    "    else:        \n",
    "        for label in range(model.numClasses):\n",
    "            for joint in range(example.shape[0]):\n",
    "                for coordinate in range(example.shape[1]):\n",
    "                    if joint == 0:\n",
    "                        output[label] += log_normpdf(example[joint,coordinate],\n",
    "                                                     model.jointparts[joint].means[coordinate,label],\n",
    "                                                     model.jointparts[joint].sigmas[coordinate,label])\n",
    "                    else:\n",
    "                        output[label] += log_normpdf(example[joint,coordinate],\n",
    "                                                     means_from_betas(model.jointparts[joint].betas[coordinate*4:(coordinate+1)*4,label], example[model.connectivity[joint], :]),\n",
    "                                                     model.jointparts[joint].sigmas[coordinate,label])\n",
    "                        \n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T14:10:01.259298Z",
     "start_time": "2020-03-30T14:10:01.243838Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.00617222, 2.00327439, 9.98813227, 4.00495957, 4.98809169,\n",
       "        5.98360449]), 0.1215204625638084)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_random_lgm_samples(n, betas, sigma):\n",
    "    \"\"\"Function to generate random samples for a \n",
    "       Linear Gaussian Model\n",
    "       Input:\n",
    "           n: Number of samples\n",
    "           betas: vector with the values the the betas from 0 to k\n",
    "           sigma: standard deviation\n",
    "    \"\"\"\n",
    "    X = np.random.randn(n,betas.shape[0]-1)\n",
    "    Y = np.random.randn(n)*sigma + np.sum(X*betas[1:],axis=1)+betas[0]\n",
    "    return X,Y\n",
    "\n",
    "betas = np.array([1,2,10,4,5,6])\n",
    "sigma = 0.1\n",
    "n=100\n",
    "X,Y=generate_random_lgm_samples(n,betas,sigma)\n",
    "# This following call should output  betas and sigma close to the above ones\n",
    "fit_linear_gaussian(Y,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predClass,labels):\n",
    "    labels = labels.squeeze()\n",
    "    out = np.sum([predClass[i] == labels[i] for i in range(len(predClass))])\n",
    "    return out/len(predClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_K_fold_cross_val(dataset,labels,K=10,G=None):\n",
    "    labels = labels.squeeze()\n",
    "    accuracies = []\n",
    "    skf = StratifiedKFold(n_splits=K)\n",
    "    \n",
    "    for train_index, test_index in skf.split(np.reshape(dataset,(2045,20,3)), labels[:]):\n",
    "        trainX, testX = dataset[:,:,train_index], dataset[:,:,test_index]\n",
    "        trainY, testY = labels[train_index], labels[test_index]\n",
    "        \n",
    "        myModel = learn_model(trainX,trainY,G)\n",
    "        probs = classify_instances(testX, myModel)\n",
    "        resultClass = np.argmax(probs, axis=1)\n",
    "        acc = accuracy(resultClass,testY)\n",
    "        accuracies.append(acc)\n",
    "\n",
    "    return (np.mean(accuracies),np.var(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leave_one_out_cross_val(dataset,labels,individuals,G=None):\n",
    "    labels = labels.squeeze()\n",
    "    individuals = individuals.squeeze()\n",
    "    accuracies = []\n",
    "\n",
    "    for ind in np.unique(individuals):\n",
    "        train_index = individuals != ind\n",
    "        test_index = individuals == ind\n",
    "\n",
    "        trainX, testX = dataset[:,:,train_index], dataset[:,:,test_index]\n",
    "        trainY, testY = labels[train_index], labels[test_index]\n",
    "\n",
    "        myModel = learn_model(trainX,trainY,G)\n",
    "        probs = classify_instances(testX, myModel)\n",
    "        resultClass = np.argmax(probs, axis=1)\n",
    "        acc = accuracy(resultClass,testY)\n",
    "        accuracies.append(acc)\n",
    "\n",
    "    return (np.mean(accuracies),np.var(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "\n",
    "d = scipy.io.loadmat('data/validation_data.mat')\n",
    "\n",
    "data_small        = d['data_small']\n",
    "labels_small      = d['labels_small'].squeeze()\n",
    "individuals_small = d['individuals_small'].squeeze()\n",
    "train_indexes     = np.array(d['train_indexes'].squeeze(),dtype=bool)\n",
    "test_indexes      = np.array(d['test_indexes'].squeeze(),dtype=bool)\n",
    "model_nb          = d['model_nb']\n",
    "model_lg          = d['model_lg']\n",
    "accur_lg          = d['accur_lg']\n",
    "accur_nb          = d['accur_nb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes: 0.95\n",
      "Linear Gaussian: 0.975\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(labels_small)\n",
    "transformed_labels_small = le.transform(labels_small)\n",
    "\n",
    "# Params of following model should be similar to those of model_nb above\n",
    "naive_bayes_model = learn_model(data_small[:,:,train_indexes],transformed_labels_small[train_indexes])\n",
    "linear_gaussian_model = learn_model(data_small[:,:,train_indexes],transformed_labels_small[train_indexes], nui_skeleton_conn)\n",
    "\n",
    "# The accuracy of naive_bayes_model on data_small[:,:,test_indexes] that have labels\n",
    "# labels_small[test_indexes] should be aprox accur_nb\n",
    "prob_NB = classify_instances(data_small[:,:,test_indexes], naive_bayes_model)\n",
    "resultClass_NB = np.argmax(prob_NB, axis=1)\n",
    "test_accuracy_NB = accuracy(resultClass_NB,transformed_labels_small[test_indexes])\n",
    "print(\"Naive Bayes:\",test_accuracy_NB)\n",
    "\n",
    "# The accuracy of linear_gaussian_model on data_small[:,:,test_indexes] that have labels\n",
    "# labels_small[test_indexes] should be aprox accur_lg\n",
    "prob_LGM = classify_instances(data_small[:,:,test_indexes], linear_gaussian_model)\n",
    "resultClass_LGM = np.argmax(prob_LGM, axis=1)\n",
    "test_accuracy_LGM = accuracy(resultClass_LGM,transformed_labels_small[test_indexes])\n",
    "print(\"Linear Gaussian:\",test_accuracy_LGM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation\n",
    "##### 10-fold cross validation\n",
    "##### leave one out cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluation on the training dataset\n",
    "\n",
    "#Load dataset\n",
    "dataset, labels, individuals = load_dataset()\n",
    "labels = labels.squeeze()\n",
    "\n",
    "#Transform labels to a form of 0 - numClasses - 1\n",
    "#This is done so we can use functions like np.argmax to get output label\n",
    "#from probabilities\n",
    "le = LabelEncoder()\n",
    "le.fit(labels)\n",
    "transformed_labels = le.transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Model Evaluation\n",
      "\n",
      "---10 Fold Cross Validation---\n",
      "(0.9427857484457197, 0.002470360785365809)\n",
      "\n",
      "---Leave One Out Cross Validation---\n",
      "(0.9425818333235602, 0.01328690037044481)\n"
     ]
    }
   ],
   "source": [
    "#Evaluating the Naive Bayes model.\n",
    "#Perfrom 10-fold cross validation and,\n",
    "#Leave one out cross validation on individuals\n",
    "\n",
    "#The output for each cross validation is a tuple,\n",
    "#of the form (mean, variance)\n",
    "\n",
    "\n",
    "print(\"Naive Bayes Model Evaluation\")\n",
    "print(\"\")\n",
    "\n",
    "print(\"---10 Fold Cross Validation---\")\n",
    "cv1_NB = stratified_K_fold_cross_val(dataset,transformed_labels,10)\n",
    "print(cv1_NB)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(\"---Leave One Out Cross Validation---\")\n",
    "cv2_NB = leave_one_out_cross_val(dataset,transformed_labels,individuals)\n",
    "print(cv2_NB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Gaussian Model Evaluation\n",
      "\n",
      "---10 Fold Cross Validation---\n",
      "(0.9833715925394546, 0.0008091374044806353)\n",
      "\n",
      "---Leave One Out Cross Validation---\n",
      "(0.9850682489839717, 0.0025799554481852355)\n"
     ]
    }
   ],
   "source": [
    "#Evaluating the Linear Gaussian model.\n",
    "#Perfrom 10-fold cross validation and,\n",
    "#Leave one out cross validation on individuals\n",
    "\n",
    "#The output for each cross validation is a tuple,\n",
    "#of the form (mean, variance)\n",
    "\n",
    "\n",
    "print(\"Linear Gaussian Model Evaluation\")\n",
    "print(\"\")\n",
    "\n",
    "print(\"---10 Fold Cross Validation---\")\n",
    "cv1_LG = stratified_K_fold_cross_val(dataset,transformed_labels,10,nui_skeleton_conn)\n",
    "print(cv1_LG)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(\"---Leave One Out Cross Validation---\")\n",
    "cv2_LG = leave_one_out_cross_val(dataset,transformed_labels,individuals,nui_skeleton_conn)\n",
    "print(cv2_LG)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122.4,
   "position": {
    "height": "40px",
    "left": "1266px",
    "right": "20px",
    "top": "120px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
